<h1 align="center">spanlp</h1>

<p align="center">
  <br>
  <i>spanlp es una librer√≠a escrita en Python para detectar, censurar  y limpiar groser√≠as, <br>
      vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en <strong>Espa√±ol</strong>.
    </i>
  <br>
  
  <p align="center">
    <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/version-v0.0.5-green"/>
    </a>
    <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/status-beta--stable-blue"/>
    </a>
  <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/release-v0.0.5-brightgreen"/>
    </a>
    <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/test--pypi-v0.0.5-yellow"/>
    </a>
  </p>
  
  <p align="center">
    <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/jfreddypuentes/spanlp?style=social">
  </p>
</p>

‚ö°‚ö° **Nuevo Release v0.0.05** ‚ö°‚ö° Implementaci√≥n de 28 algoritmos de limpieza y pre-procesamiento de datos

<hr>

## Indice
- [Indice](#indice)
- [Sobre la librer√≠a](#sobre-la-librer√≠a)
- [Casos de uso](#casos-de-uso)
- [Status Desarrollo](#status-desarrollo)
- [Instalaci√≥n](#instalaci√≥n)
- [Funcionamiento](#funcionamiento)
  - [Uso b√°sico](#uso-basico)
  - [Uso avanzado](#uso-avanzado)
  - [Pre-procesamiento de datos](#preprocesamiento-de-texto) ‚ö°‚ö° **Nuevo v0.0.5** ‚ö°‚ö°
- [Beta Testing](#beta-testing)
- [Reportar un bug](#reportar-un-bug)
- [Contacto](#contacto)

<hr>

## Sobre la librer√≠a
spanlp es una librer√≠a escrita en Python para detecci√≥n de groser√≠as, vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en Espa√±ol. Puedes usar la librer√≠a y aplicarla a palabras de cualquiera de los m√°s de **20 paises** de habla hispana.

Incluye:
1. Argentina üá¶üá∑
2. Bolivia üáßüá¥
3. Chile üá®üá±
4. Colombia üá®üá¥
5. Costa Rica üá®üá∑
6. Cuba üá®üá∫
7. Ecuador üá™üá®
8. El Salvador üá∏üáª
9. Espa√±a üá™üá∏
10. Guatemala üá¨üáπ
11. Guinea Ecuatorial üá¨üá∂
12. Honduras üá≠üá≥
13. M√©xico üá≤üáΩ
14. Nicaragua üá≥üáÆ
15. Panam√° üáµüá¶
16. Paraguay üáµüáæ
17. Per√∫ üáµüá™
18. Puerto Rico üáµüá∑
19. Rep√∫blica Dominicana üá©üá¥
20. Uruguay üá∫üáæ
21. Venezuela üáªüá™

## Casos de uso
* Censurar vulgaridades en un texto.
* Detectar y censurar vulgaridades en una sala de chat en linea.
* Encontrar y censurar frases y palabras de odio, racismo, xenofia, bullying. (Se deben incluir como par√°metros)
* Censurar comentarios groseros o insultos en alg√∫n blog o aplicaci√≥n web o sitio web.
* Censurar malas palabras en un sistema de recolecci√≥n de opiniones, sugerencias, quejas y reclamos.
* Limpiar textos antes de ser publicados.
* Detectar y eliminar vulgaridades en textos que ser√°n leidos y/o vistos por ni√±os.
* Limpiar una base de datos con mucho texto.

## Status Desarrollo

| Funcionalidad                     | Desarrollo |   Pruebas   | Release  |
|-----------------------------------|------------|-------------|-----------
| Soporte de tokens con n√∫meros     |     ‚úì      |     OK      | v0.0.5   |  
| Estrategias de limpieza de datos  |     ‚úì      |     OK.     | v0.0.5   |

## Instalaci√≥n
**Nota:** Esta versi√≥n se encuentra en Beta. No la use en producci√≥n a√∫n. 
Te recomiendo que la instales, pruebes y haz doble check sobre los resultados.
Si encuentras alg√∫n problema escribeme o puedes crear un issue [aqu√≠](https://github.com/jfreddypuentes/spanlp/issues/new)

```console
pip install -i https://test.pypi.org/simple/ spanlp
```

## Funcionamiento
Los algoritmos y modulos se personalizan de forma din√°mica y muy flexible. Veamos algunos usos.

### Uso b√°sico

Validar si una palabra o frase contiene o no una palabrota:
```python
from spanlp.palabrota import Palabrota
palabrota = Palabrota()
print(palabrota.contains_palabrota("Hola huevon c√≥mo est√°?"))
# salida: True
```

```python
from spanlp.palabrota import Palabrota
palabrota = Palabrota()
print(palabrota.contains_palabrota("Hola a todos ¬øc√≥mo est√°n?"))
# salida: False
```

Censurar una frase con los par√°metros por defecto:

```python
from spanlp.palabrota import Palabrota

palabrota = Palabrota()
print(palabrota.censor("Hola huevon c√≥mo est√°?"))

# salida: Hola !$%#@! c√≥mo est√°?
```

Censurar la misma frase, configurando car√°cteres propios

```python
from spanlp.palabrota import Palabrota

palabrota = Palabrota(censor_char="*")
print(palabrota.censor("Hola huevon como est√°?"))

# salida: Hola ****** c√≥mo est√°?
```

Censurar otra frase, configurando car√°cteres propios y pa√≠s

```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.COLOMBIA, Country.VENEZUELA])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola @@@@@@ @@@@@@ c√≥mo est√°?
```

Censuremos la misma frase pero solo con el pa√≠s de Venezuela
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.VENEZUELA])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola huevon @@@@@@ c√≥mo est√°?
```

Censuremos la misma frase pero incluyendo "huevon" al vocabulario de Venezuela
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.VENEZUELA], include=["huevon"])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola @@@@@@ @@@@@@ c√≥mo est√°?
```

Censuremos la misma frase incluyendo "huevon" al vocabulario de Venezuela y excluyendo "marico"
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.VENEZUELA], include=["huevon"], exclude=["marico"])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola huevon marico c√≥mo est√°?
```

Censuremos la misma frase incluyendo ""Hola" y "huevon" al vocabulario de Venezuela y excluyendo "marico"
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="-", countries=[Country.VENEZUELA], include=["huevon"], exclude=["marico"])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: ---- ---- marico c√≥mo est√°?
```

### Uso Avanzado
El uso avanzado incluye usar metricas de distancia y similitud para encontrar, comparar, censurar palabras.
Estas son las metrcias usadas a la fecha:
1. [Indice de Jaccard](https://es.wikipedia.org/wiki/%C3%8Dndice_Jaccard) ([Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index))
2. [Similitud del coseno](https://es.wikipedia.org/wiki/Similitud_coseno) ([Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity))

Pr√≥ximos releases:
* Hamming...
* Levenstein...
* Bag distance...
* Sorensen-Dice coefficient...
* Tversky index...
* Overlap index...
* Tanimoto distance...


Censuremos la frase usando Cosine Similarity 
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import CosineSimilarity

palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=CosineSimilarity())
print(palabrota.censor("Hola huevo maric c√≥mo est√°?"))

# salida: Hola huevo ***** c√≥mo est√°?
```
A pesar de que "maric" no est√° en el dataset, al algoritmo la censur√≥ dado que por la m√©trica de distancia es muy similar. 


Censuremos la frase usando **Cosine Similarity** manipulando los par√°metros
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import CosineSimilarity

# Indicamos que tenga en cuenta palabras similares en al menos 30% y que normalice los datos (poner en minusculas, remover acentos)
cosine = CosineSimilarity(0.9, normalize=True) 
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=cosine)
print(palabrota.censor("Hola huevon MARIC c√≥mo est√°?"))

# salida: hola huevon ***** **** esta? => Censur√≥ "como" porque en el dataset est√° "cono" y son similares en m√°s del 90%
```

Censuremos la frase usando **JaccardIndex** con los par√°metros por defecto
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=JaccardIndex())
print(palabrota.censor("Hola huevo maric c√≥mo est√°?"))

# salida: Hola huevo ***** c√≥mo est√°?
```
El indice de Jaccard usa por defecto los siguientes par√°metros:
* `threshold=0.8` - Indica que censurar√° palabras con una similitud del 80% o m√°s.
* `normalize=False` - False indica que no pasar√° el texto a minuscula y no remover√° acentos.
* `n_gram=2` - Usa 2 subsecuencias de la palabra. (Ver [N-grama](https://es.wikipedia.org/wiki/N-grama))

Censuremos la frase usando **JaccardIndex** y modifiquemos los par√°metros
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.9, normalize=True, n_gram=1)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: hola huevon ****** **** vamos?
```

Ahora, sin normalizar los datos
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.9, normalize=False, n_gram=1)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: Hola huevon ****** c√≥mo vamos? => "moco" y "c√≥mo" ahora son muy diferentes.
```

Ahora, bajemos el `threshold` a `0.6`
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.6, normalize=False, n_gram=1)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: Hola ****** ****** c√≥mo vamos? => Ha censurado una palabra m√°s.
```

Aumentemos la cantidad de `n_gram` a `3` con el `threshold=0.7` y con `normalize=False`
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.7, normalize=False, n_gram=3)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: Hola huevon marica c√≥mo vamos? => No censur√≥ nada.
```

## Preprocesamiento de texto
Siempre ser√° necesario limpiar los datos antes de empezar a trabajar. Aqui te presento la clase `Preprocessing` y las 28 estrat√©gias de limpieza de datos.

¬øCuantas estrategias hay y cuales son?

Son 28 algoritmos y son:

1.`TextToLower`
2.`TextToUpper`
3.`RemoveUnicodeCharacters`
4.`NumbersToVowelsInLowerCase`
5.`NumbersToVowelsInUpperCase`
6.`NumbersToConsonantsInLowerCase`
7.`NumbersToConsonantsInUpperCase`
8.`RemoveExtraSpaces`
9.`RemoveUserMentions`
10.`RemoveUrls`
11.`RemoveHashtags`
12.`RemoveTicks`
13.`RemoveBackTicks`
14.`RemovePunctuation`
15.`RemoveNumbers`
16.`RemoveAccents`
17.`RemoveStopWords`
18.`RemoveArticles`
19.`RemoveEmoticons`
20.`RemovePronouns`
21.`RemoveAdverbs`
22.`RemoveConjunctions`
23.`RemovePrepositions`
24.`RemoveAdjectives`
25.`RemoveHtmlTags`
26.`RemoveEmailAddress`
27.`ExpandAbbreviations`
28.`RemoveAbbreviations`


La nueva clase `Preprocessing` implementa de manera flexible y din√°mica cualquier estrategia de limpieza de una manera muy simple. Se puede aplicar dentro de una metrica de distancia como `JaccardIndex` o `CosineSimilarity` para darle m√°s poder a la busqueda, dismunir el riesgo de no encontrar las palabras a censurar y aumentar la posibilidad de censurar las palabras que son por el hecho de estar limpias.


Veamos algunos ejemplos:

```python
from spanlp.domain.strategies import Preprocessing, TextToLower

strategies = [TextToLower()] # Defino mis estrategias de limpieza o pre-procesamiento
data = "ESTARE EN MINUSCULA" # Tengo mis datos
result = Preprocessing(data=data, clean_strategies=strategies).clean() # Invoco a Preprocessing
print(result)

# salida: estare en minuscula
```

Tambien se puede as√≠:
```python
from spanlp.domain.strategies import Preprocessing, TextToLower

strategies = [TextToLower()]
data = "ESTARE EN MINUSCULA" 
result = Preprocessing().clean(data=data, clean_strategies=strategies) # Envio los datos y las estragias al clean()
print(result)

# salida: estare en minuscula
```

Y tambien as√≠:
```python
from spanlp.domain.strategies import Preprocessing, TextToLower

strategies = [TextToLower()]
data = "ESTARE EN MINUSCULA"
preprocessor = Preprocessing(data=data, clean_strategies=strategies)
result = preprocessor.clean()
print(result)

# salida: estare en minuscula
```

Y as√≠:
```python
from spanlp.domain.strategies import Preprocessing, TextToLower

result = Preprocessing(data="ESTARE EN MINUSCULA", clean_strategies=[TextToLower()]).clean()
print(result)

# salida: estare en minuscula
```


## Beta Testing
¬øEres betatester? ¬øquieres automatizar pruebas? o ¬øsimplemente aprender del open source y de las pruebas? Aventurate ya y ayudame a mejorar este proyecto!
A continuaci√≥n encontrar√°s algunas pautas para implementar pruebas exitosas que permitar√°n encontrar posibles errores y mejoras.

### 1. ¬øPor donde empezar?
* Instalar python.
* Instalar la librer√≠a. Esto lo logras ejecutando en la terminal el comando: `pip install -i https://test.pypi.org/simple/ spanlp`
* Abre un nuevo script de python, importa la librer√≠a y empieza a experimentar.

### 2. ¬øQu√© tipos de pruebas puedo realizar?
Excelente pregunta! no hay limite para la creatividad; As√≠ que haz todas las pruebas que quieras e imagines. Sin embargo, aqu√≠ te dejo algunas pautas:

* **Pruebas de caja negra** => Una vez instales la librer√≠a y hayas leido la documentaci√≥n; Trata de usarla sin preocuparte como funciona o como obtuvo el resultado (Las pruebas no se hacen en base al c√≥digo, sino a la interfaz); Eso si, valida que la salida o el resultado sea el que esperas. Te puedes guiar (pero no mucho) de las pruebas unitarias que est√°n en: `/spanlp/tests/test_palabrota.py`

* **Pruebas de caja blanca** => Si quieres vez como funciona la libreria, estas pruebas son las tuyas. Intenta entender la estructura, los algoritmos y flujos. Una vez los comprendas, "a dar palo", trata de quebar o romper la l√≥gica, observa y encuentra si hay posibles formas de hacer que falle, prueba diferentes parametros, flujos, tipos de datos. Haz que falle, haz que se ponga lento! y me cuentas. ;)

* **Pruebas de carga y stress** => Si lo tuyo son las pruebas de requisitos no funcionales, te invito a que sigas estos pasos para estresar la libreria y medir que tan escalable es frente a procesos de alta carga, mide la velocidad y que tan bien se comparta con miles o millones de hilos usandola al tiempo.

Sigue estos pasos:

1. Crear una API Rest s√∫per simple. Crea el siguiente script y ll√°malo `server.py` 

```console
pip install flask
```

```python
from flask_cors import CORS, cross_origin
from flask import request
from flask import json

from spanlp.palabrota import Palabrota

app = Flask(__name__)
cors = CORS(app)

@app.route('/api/v1/nlp/text/censor', methods = ['POST'])
@cross_origin()
def censor():
    try:
        body = request.json     
        in_message = body['message']
        
        if in_message and len(str(in_message).strip()):
            palabrota = Palabrota()
            censored = palabrota.censor(in_message)
            response = {
                "success": True,
                "message": "OK",
                "error_code": 0,
                "data": {
                    'message': in_message,
                    'censored': censored
                }
            }
            return response
        else:
            return {
                "success": False,
                "message": "Bad Request - message is required",
                "error_code": 400,
                "data": {}
            }
    except Exception as e:
        return {
            "success": False,
            "message": "Internal Server Error - "+str(e),
            "error_code": 500,
            "data": {}
        }


if __name__ == '__main__':
    app.run(host='127.0.0.1', port=8080, debug=True)
```


```
python server.py
```

y listo!! 


2. Consume la API desde alg√∫n cliente http como [Postman](https://www.postman.com/), [Insomnia](https://insomnia.rest/download/) y/o [SOAP UI](https://www.soapui.org/). Tambien puedes usar alguna herramienta como [Apache JMeter](https://jmeter.apache.org/); o tambien puedes crear un script python con muchos hilos que consuma la API.


### 3. ¬øquieres escibrir unit tests y ejecutarlo de forma autom√°tica?
Clona el repositorio en tu m√°quina, abre el proyecto en tu editor favorito, ve al archivo `/spanlp/tests/test_palabrota.py` y empieza a escribir tus propios tests unitarios. Escribe cuantos quieras.
Una vez tengas los tests listos, ejecuta el siguiente comando en la raiz del proyecto (`/spanlp/`):

```console
pytest -ra
```

Esto ejecutar√° de forma autom√°tica todas las pruebas programadas e indicar√° si algun test fall√≥.


## Reportar un bug
Si encuentras alg√∫n problema (por muy m√≠nimo que sea) reportalo [aqu√≠](https://github.com/jfreddypuentes/spanlp/issues/new). Solo necesitar√°s poner t√≠tulo y describir la falla y aportar√° un mont√≥n a que este proyecto mejore su calidad.


## Contacto
¬øAlguna duda? escribeme por email:  [jfredypuentes@gmail.com](mailto:jfredypuentes@gmail.com)

Cuentame en ([@jfreddypuentes](https://twitter.com/jfreddypuentes)) ¬øqu√© te parece est√° librer√≠a? ¬øc√≥mo la est√°s usando? ¬øQu√© le mejorar√≠as?

<br>
<br>


**Hecho con ‚ù§Ô∏èÔ∏è de Colombia para el mundo.**
